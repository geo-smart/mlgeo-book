{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Neural Networks \n",
    "\n",
    "A linear regression is a single, fully connected neuron.\n",
    "\n",
    "![Single Neuron](../img/TLU.png)\n",
    "Figure: Extracted from \"Hands on Maching Learning using Keras and Tensorflow\"\n",
    "\n",
    "\n",
    "The simplest neural network is a logistic regression\n",
    "\n",
    "$y = f( \\sum_{i=1}^3  (w_i x_i + b_i))$,\n",
    "\n",
    "where $y$ is the output, $w_i$, are the weights, $b_i$ are the biases in the neuron, and $f$ is an activation function (e.g., sigmoid, ReLu, etc)\n",
    "\n",
    "For classification problem, it is called a Threshold Logic Unit TLU because it outputs a linear combination of the inputs, and if the result exceeds a threshold, it outputs the positive class.\n",
    "\n",
    "A perceptron is a single layer of TLUs, which each TLU connected to all the inputs. \n",
    "\n",
    "**Logistic regression: It is just a one layer neural network classifier**\n",
    "\n",
    "We will explore the classification problem with NN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a data set\n",
    "\n",
    "We will read a dataset and convert into a format readable by PyTorch.\n",
    "\n",
    "We are going to do multi-class classification. We have a dataset of images of digits (0 to 9). Each image is made of 16 * 16 pixels in grey scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x1c135a7f0>\n",
      "torch.Size([50, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import load_digits,fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.transforms import transforms, ToTensor, Compose,Normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "\n",
    "dataset = datasets.MNIST(root=\"./\",download=True,\n",
    " transform=Compose([ToTensor(),Normalize([0.5],[0.5])]))\n",
    "L=len(dataset)\n",
    "Lt = int(0.8*L)\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [Lt,L-Lt])\n",
    "loaded_train = DataLoader(train_set, batch_size=50)\n",
    "loaded_test = DataLoader(val_set, batch_size=50)\n",
    "print(loaded_train)\n",
    "\n",
    "X, y = next(iter(loaded_train))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second  approach is to prepare the data from zip files and convert them to torch tensors. The training file and the test file are made of 257 columns: the first column is the label, the next 256 columns are the corresponding value for each of the 16 * 16 = 256 pixels. There is one image per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is a class already defined in PyTorch. \n",
    "# We are going to create a subclass of Dataset\n",
    "class ZipDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transforms=None):\n",
    "        # Let us define the attributes of a ZipDataset\n",
    "        self.X = images # that will be train_images or test_images\n",
    "        self.y = labels # that will be train_labels or test_labels\n",
    "        # When we create an object of class ZipDataset, we can specify the transformation to apply to the data \n",
    "        self.transforms = transforms\n",
    "         \n",
    "    def __len__(self):\n",
    "        # The length of the dataset is the number of images in the dataset\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # How to access one pair of (image, label) from the dataset?\n",
    "        # We access the ith row (which contains the 16*16 = 256 pixels of an image)\n",
    "        data = self.X.iloc[i, :]\n",
    "        # We transform it into a numpy array and reshape it to an image format\n",
    "        data = np.asarray(data).reshape(16, 16, 1)\n",
    "        # We apply the required transformation to the image\n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "        # If there is a label associated to it, we return it together with the image\n",
    "        if self.y is not None:\n",
    "            return (data, self.y[i])\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('zip.train', header=None, sep='\\s+')\n",
    "df_test = pd.read_csv('zip.test', header=None, sep='\\s+')\n",
    "train_labels = df_train.iloc[:, 0]\n",
    "train_images = df_train.iloc[:, 1:]\n",
    "test_labels = df_test.iloc[:, 0]\n",
    "test_images = df_test.iloc[:, 1:]\n",
    "\n",
    "train_data = ZipDataset(train_images, train_labels, ToTensor())\n",
    "test_data = ZipDataset(test_images, test_labels, ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.ZipDataset object at 0x1bfa3c4f0>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch uses a class to manipulate Datasets called [DataLoader](https://pytorch.org/docs/stable/data.html). It has methods such as iteration, indexing, mini-batching, sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_data)\n",
    "testloader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Design Model\n",
    "\n",
    "The first neural networks we will create is a single neuron that takes the images as input and output the probability in each of the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a subclass of neural networks: \n",
    "# #This one will just have one layer\n",
    "\n",
    "class NN1(nn.Module): # a class defines an object\n",
    "\n",
    "\n",
    "    # this defines the arcitecture of the NN\n",
    "    def __init__(self, size_img, num_classes):\n",
    "        # Here we define all the functions that we will use during the forward part (data -> prediction)\n",
    "        \n",
    "        # super means that the model will inherit all of the methods\n",
    "        super(NN1, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.flatten = nn.Flatten() # go from a 16*16 tensor to a 256*1 tensor\n",
    "        self.size_img = size_img # number of pixels in an image\n",
    "        self.layer1 = nn.Linear(size_img, num_classes) # y = wx + b with w = 10*256 (10 digits * 256 pixels)\n",
    "\n",
    "\n",
    "    # this defines how the data passes through the layers\n",
    "    def forward(self, x):\n",
    "        # Here we explain in which order to use the functions defined above\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layer1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a model of the class NN1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN1(28*28, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Define Loss Function\n",
    "\n",
    "For the binary classification, we had defined the logistic function or *sigmoid* function as,\n",
    "\n",
    "$\\hat{y} = \\frac{1}{1 + e^{-z}}$,\n",
    " \n",
    "as the probability function for a binary classifier.\n",
    "\n",
    "The log loss function to minimize is:\n",
    "\n",
    "$\\mathcal{L} =  - (y \\log \\hat{y} + (1 - y) \\log (1 - \\hat{y})$ with $\\hat{y} = \\frac{1}{1 + e^{-z}}$.\n",
    "\n",
    "We wanted to find all of the weights $w$ and biases $b$ such that $P(Y = y)$ is maximum, which is equivalent to minimizing the loss $\\mathcal{L}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a multi-class classification, $k$ being the class and $K$ the number of classes, the sigmoid function is extended to a *softmax function*,\n",
    "\n",
    "$P(Y = k) = \\frac{\\exp(w_k x + b_k)}{\\sum_{j = 1}^K \\exp(w_j x + b_j)}$\n",
    "\n",
    "Once we have found the values of the $w_k$ and $b_k$ for $k = 1 , \\cdots , K$, we can compute the values of the $P(Y = k)$. We then look for which value of $k$ $P(Y = k)$ is maximal and we classify this sample as class $k$.\n",
    "\n",
    "\n",
    "Similarly, we define the loss with $K$ classes:\n",
    "\n",
    "$\\mathcal{L} = - \\sum_{k = 1}^K y_k \\log \\frac{\\exp(w_k x + b_k)}{\\sum_{j = 1}^K \\exp(w_j x + b_j)}$. We have $y_k = 1$ if the true label associated with the sample $x$ is $k$, otherwise $y_k = 0$.\n",
    "\n",
    "This is called the _cross-entropy loss_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Define optimization\n",
    "\n",
    "*Gradient descent* uses the entire data set to compute the gradient and find the optimal (minimum loss) solution. Effectively, the batch size is the entire data set.\n",
    "\n",
    "*Mini batch gradient descent* uses batches of data to compute the gradient, find a solution, and moves to the next set of training data. The batch size is determined. The prediction on the training set is calculated for each sample in the batch, then averaged. Then the gradient is calculated.\n",
    "\n",
    "*Stochastic gradient descent* uses one data sample to calculate the gradient, finds a solution, then take another training sample to go down the gradient. Effectively, the batch size is 1.\n",
    "\n",
    "\n",
    "In this example, we will use stochastic gradient descent SGD.\n",
    "\n",
    "Parameters to choose are:\n",
    "* optimizer (gradient descent or others)\n",
    "* learning rate (scale to jump with the gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Define a training strategy\n",
    "\n",
    "Parameters to choose are:\n",
    "* **batch size**: this is the size of an individual training set used to estimate an average model prediction loss, after which a gradient will be calculated, and the model weights updated.\n",
    "* **number of epochs**: this is the number of times the training goes over the *entire* data sets. If the training set is split into batches of size ``batch_size``, then at each **epoch**, the training will be performed over all batches. Models tend to be trained over multiple-to-many epochs (10,100,1000). \n",
    "\n",
    "Let us now define how to train the model. We will create a function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epochs, trainloader, testloader=None,learning_rate=0.001 ):\n",
    "\n",
    "    # Define loss and optimization method\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # # Save loss and error for plotting\n",
    "    loss_time = np.zeros(n_epochs)\n",
    "    accuracy_time = np.zeros(n_epochs)\n",
    "\n",
    "    # # Loop on number of epochs\n",
    "    for epoch in range(n_epochs):\n",
    "    #     # Initialize the loss\n",
    "        running_loss = 0\n",
    "    #     # Loop on samples in train set\n",
    "        for data in trainloader:\n",
    "    #         # Get the sample and modify the format for PyTorch\n",
    "            inputs, labels = data[0], data[1]\n",
    "            inputs = inputs.float()\n",
    "            print(inputs.shape)\n",
    "            labels = labels.long()\n",
    "    #         # Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            print(labels)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "    #         # Propagate the loss backward\n",
    "            loss.backward()\n",
    "    #         # Update the gradients\n",
    "            optimizer.step()\n",
    "    #         # Add the value of the loss for this sample\n",
    "            running_loss += loss.item()\n",
    "    #     # Save loss at the end of each epoch\n",
    "        loss_time[epoch] = running_loss/len(trainloader)\n",
    "\n",
    "    #     # After each epoch, evaluate the performance on the test set\n",
    "        if testloader is not None:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "    #         # We evaluate the model, so we do not need the gradient\n",
    "            with torch.no_grad(): # Context-manager that disabled gradient calculation.\n",
    "    #             # Loop on samples in test set\n",
    "                for data in testloader:\n",
    "    #                 # Get the sample and modify the format for PyTorch\n",
    "                    inputs, labels = data[0], data[1]\n",
    "                    inputs = inputs.float() \n",
    "                    labels = labels.long()\n",
    "    #                 # Use model for sample in the test set\n",
    "                    outputs = model(inputs)\n",
    "    #                 # Compare predicted label and true label\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "    #         # Save error at the end of each epochs\n",
    "            accuracy_time[epoch] = 100 * correct / total\n",
    "    \n",
    "    #     # Print intermediate results on screen\n",
    "        if testloader is not None:\n",
    "            print('[Epoch %d] loss: %.3f - accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss/len(trainloader), 100 * correct / total))\n",
    "        else:\n",
    "            print('[Epoch %d] loss: %.3f' %\n",
    "              (epoch + 1, running_loss/len(trainloader)))\n",
    "\n",
    "    # # Save history of loss and test error\n",
    "    if testloader is not None:\n",
    "        return (loss_time, accuracy_time)\n",
    "    else:\n",
    "        return (loss_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# (loss, error) = train(model, 10,trainloader, testloader, learning_rate)\n",
    "(loss, accuracy) = train(model, 10,loaded_train, loaded_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now plot the evolution of the loss and the percentage of correct predictions with time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/yklEQVR4nO3dd3SUVf7H8c8kk0zapFdI6EFMaJHiKmBBYG2srm2x4qor7oKiWEFdEJWAa1nXgrKCroVF/IGKvaAiRQWVIBI6CCGUdDIJySSTeX5/oOOOGRCGMGMe3q9z5pzMfe69+d7I2fnsfcpYDMMwBAAAgFYvJNgFAAAAoGUQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAlrsAswA5fLpZUrVyotLU0hIWRlAAAOh9vt1p49e5SXlyerlWhyJPjrtYCVK1eqf//+wS4DAIBWbfny5erXr1+wy2jVCHYtIC0tTdL+f5AZGRlBrgYAgNZl165d6t+/v+fzFP4j2LWAn06/ZmRkKDMzM8jVAADQOnE505HjLwgAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyi1QW7itmztemMIVrXs5e2XnCh9n399UH71y5frq0XXKh1PXtp05Chqpwz54B9977zjtZ2O15Fo8e0dNkAAKCFvfTFDxo47RN1vec9nfvEYi3fWnHQ/l9uKde5TyxW13ve06CHPtHLX247YN8Fq3aqw13v6C8vHjxn/Na0qmBX/e672pM/VUk3jFLH1+crsm8fbb9+lBp37vTZv2HHDhWNukGRffuo4+vzlTTqeu1+cIqqP/iwWd/G4mKVPPQPRfbtc7SXAQAAjtBbq3Zq8tuFGnN6F71700D165Coq59fruKqOp/9iyr26c/Pr1C/Dol696aBGn1aF9331hq9t3pXs747Kvdpyjtr1b9D4tFeRotrVcGu/IX/KP7CC5Rw8cWyde6s9AkTFJaersr/+t6Fq5ozR2EZGUqfMEG2zp2VcPHFir/gAlXMmuXVz2hqUvHtdyjlxjEKz8wKxFIAAMAReG7JVl3SN0sj+rdTl1S7Jg7PVUZcxAF34V7+apvaxEdo4vBcdUm1a0T/drq4b5ZmLN7i1a/JbejmOQW6ZWi2shKjArGUFtVqgp3R0KD6NWsUPWCAV3v0gAGqW7nS55h9BQXN+w8coLo1a2Q0Nnrayp56WqGJCYq/6KJDqsXpdKq6utrzcjgch7kaAADwSw6Hw+vz1el0+uzX4HLr++K9GpSd4tU+KDtF32yr9Dlm5baqZv1PyU7R6h171djk9rQ9vnCjEqPD9ad+7Y5wNcHRaoKdq7JKamqSNSnZq92alCRXWZnPMU2lZbImJf2if7LkcslVuf8//L5vv1XVvHnKuP/+Q64lPz9fcXFxnldOTs7hLQYAADSTk5Pj9fman5/vs1/lvgY1uQ2l2MO92lPsNpU5fIfB0hqnUuy2X/QPl8ttqLK2QZL09Q8VmruiSFMv7NkCqwkOa7ALOGyWXzYYkqVZ4//0/+Ux48dmi5pqarXz9juUcf9kWRMSDrmE8ePHa9y4cZ73xcXFhDsAAI5QYWGh2rZt63lvs9kO0lv6ZSgwDMNHTjgww/h5mhqnSze/WqD8C3soMTr8oON+y1pNsLMmxEuhoc1251zlFc125X4SmpLso3+5ZLUqND5ezk2b1FhcrKK//u3nDu7927Frc7ur83vvKrxd861Ym83m9Y+turraz1UBAICf2O12xcbG/mq/hKhwhYZYVPqL3bmymgYlx/gOgykxNp/9rSEWJUSFa8Meh3ZU1um6//x8F6z7x+TXecK7+uTWU9U+KfpwlxRwrSbYWcLDFZGbq9plyxQ7dKinvXbZMtkHD/Y5Jqp3bzk+/cyrrXbpUkXm5soSFqbwTp3UccGbXsdLH/+X3LW1SpswXmHp6S2+DgAAcGTCrSHq3jZOSzaV6szuP39WL9lUpqE5aT7H5LWP18K1JV5tizeWqkdmnMJCQ9Q5JUYf3HyK1/GHP1yvWqfrxxszIlt+IUdBqwl2kpR09UgV33mXIrt3V2Tv3qqaO1eNu3YpYcSfJEkljzwqV8ketZk2TZIUP2KEKl6ZrT35UxV/ycWqKyhQ1bz5avvww5KkEJtNEV27ev2OULtdkpq1AwCA347rBnbUuLkF6tk2Xie0j9fsr4q0s6pOl5+4/0zbtPfXac/eej36p96SpCtObK8Xl23T/W8X6tL+Wfp2W5Xmfl2kf43IkyRFhIXquHS71++IjQiTpGbtv2WtKtjFnn22XFVVKnvqablKS2XLzla7Z59R2I/n412lpWrc+fPzaMIzM5X17DPaM3WqKmfPljU1Vel3T1Ds74cFawkAAKAFDO/VRlX7GvT4wo0qdTjVNT1Gz1/dT5kJ+x9RUlLt9HqmXVZilJ7/cz/d/3ahXvpim1JjbZo4PFdn9cgI1hKOCotheC4dhJ927NihrKwsFRUVKTMzM9jlAADQqvA52nJazeNOAAAAcHAEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASViDXcDhqpg9WxUzZ8lVWipbly5KmzBeUX37HrB/7fLlKpk6Tc5Nm2RNTVXSddcqYcQIz/HKuXO1980Fcm7cKEmKyM1R6i23KLJnz6O+FgAA4L+XvvhBz36+RSUOp7qmxejv5+aqf8fEA/b/cku5HninUBv21Cgt1qZRp3TWFb9r7zn+3+XbNf/bHVq/2yFJ6pEZp9t/3029s+KP9lJaTKvasat+913tyZ+qpBtGqePr8xXZt4+2Xz9KjTt3+uzfsGOHikbdoMi+fdTx9flKGnW9dj84RdUffOjps2/5CsWec7ba/+cFdZjzX4VltNH2a69T4549gVoWAAA4TG+t2qnJbxdqzOld9O5NA9WvQ6Kufn65iqvqfPYvqtinPz+/Qv06JOrdmwZq9GlddN9ba/Te6l2ePl9uKdcferXRf6//neb/bYDaxEXqyplfaffe+kAt64i1qmBX/sJ/FH/hBUq4+GLZOndW+oQJCktPV+V/5/jsXzVnjsIyMpQ+YYJsnTsr4eKLFX/BBaqYNcvTp+3D/1DiZZcp4vjjZevUSRn3T5bcbtV+8UWglgUAAA7Tc0u26pK+WRrRv526pNo1cXiuMuIi9PKX23z2f/mrbWoTH6GJw3PVJdWuEf3b6eK+WZqxeIunz+Mj8nTlSR2U2yZOXVJjNPXCnjIMaemmskAt64i1mmBnNDSofs0aRQ8Y4NUePWCA6lau9DlmX0FB8/4DB6huzRoZjY0+x7jr6mW4XAqNiztgLU6nU9XV1Z6Xw+E4zNUAAIBfcjgcXp+vTqfTZ78Gl1vfF+/VoOwUr/ZB2Sn6ZlulzzErt1U1639KdopW79irxia3zzF1jU1qbHIrPirMj9UER6sJdq7KKqmpSdakZK92a1KSXGW+k3RTaZmsSUm/6J8suVxyVfr+D1/66COypqUp+uSTD1hLfn6+4uLiPK+cnJzDWwwAAGgmJyfH6/M1Pz/fZ7/KfQ1qchtKsYd7tafYbSpz+A6DpTVOpdhtv+gfLpfbUGVtg88x095bp/S4CA3okuzz+G9Rq7t5QpZfNhiSpVnj//T/5THjx+bmY8qfe05733lX7V/8j0JstmbHfzJ+/HiNGzfO8764uJhwBwDAESosLFTbtm09720H+Szez/uz3DAMHznhwAzD5zSSpGcWbdaCVTs15/rfKSIs9NAnDbJWE+ysCfFSaGiz3TlXeUWzXbmfhKYk++hfLlmtCo2P92ovnzlLZc/OULtZsxRx3HEHrcVms3n9Y6uurj70hQAAAJ/sdrtiY2N/tV9CVLhCQywq/cXuXFlNg5JjfIfBlBibz/7WEIsSorx3/mZ8vllPfbpJr1x3oo7P+PV6fktazalYS3i4InJzVbtsmVd77bJliszL8zkmqnfv5v2XLlVkbq4sYT+fLy+fOVNl06er3b9nKLJH95YvHgAAtJhwa4i6t43Tkk2lXu1LNpWpT/sEn2Py2sdryS9ugli8sVQ9MuMUFvpzHHp20WY9sXCT/nNNf/XMjG/x2o+2VhPsJCnp6pGq+r95qpo3T87Nm7UnP1+Nu3YpYcSfJEkljzyqnXfe6ekfP2KEGnfu1J78qXJu3qyqefNUNW++Eq+5xtOn/LnnVPrPx5Xx4IMKa9tWrtJSuUpL5a6tDfj6AADAobluYEe9uqJIc1cUaVOJQ5PfKtTOqjpdfmI7SdK099dp3KsFnv5XnNhexZV1uv/tQm0qcWjuiiLN/bpI1w/q5OnzzKLNeuTDDXroop7KTIhUiaNeJY561TpdgV6e31rNqVhJij37bLmqqlT21NP7H1Ccna12zz6jsB/Px7tKS9W48+fn0YRnZirr2We0Z+pUVc6eLWtqqtLvnqDY3w/z9Kmc/V8ZjY0qHjvW63cljx6tlBvHBGZhAADgsAzv1UZV+xr0+MKNKnU41TU9Rs9f3U+ZCVGSpJJqp9cz7bISo/T8n/vp/rcL9dIX25Qaa9PE4bk6q0eGp89LX2xTQ5Nbf33lW6/fNfaMbN0ytGtgFnaELIbhuXQQftqxY4eysrJUVFSkzMzMYJcDAECrwudoy2lVp2IBAABwYAQ7AAAAk2hV19gBAACYwc6qOlksUkZcpCSpoKhKbxYUKzvVrst+vAHEH+zYAQAABNjYOSv1xeZySVKJo15XPveVVhVV6R8frNPjH2/0e16CHQAAQICt3+1Qr6x4SdI73+1S13S75v9tgB4fkaf/+7bI73kJdgAAAAHmchsK//HByEs3lWnI8WmSpM6pMSqp9v19t4eCYAcAABBg2Wl2vfLVdi3fWqHFG8t0atcUSdKe6vpmX3F2OAh2AAAAAXbXmd00+6ttGjHjC/2hVxvltNn/nbQfF+5Rr6w4v+flrlgAAIAAO6lzklb+fZhq6l2Ki/r5++sv7d9OkeGhfs9LsAMAAAiC0BCLV6iT9n/12ZEg2AEAAARYqcOpKe+u1dJNZSqvbdAvv+F1S/45fs1LsAMAAAiw215bpZ1VdbrxjGyl2m2ytNC8BDsAAIAA+/qHCs294STltvH/RglfuCsWAAAgwDLiI/WLs68tgmAHAAAQYH8/N0fT3l+noop9LTovp2IBAAACbMzsb1Xf6Nap//hUkWGhsoZ677WtmjjMr3kJdgAAAAH29+G5R2Vegh0AAECAXdQn86jMS7ADAAAIgia3oQ/X7NamkhpZLFKXVLuG5qQpNMT/h58Q7AAAAALsh7Ja/fmFFdq9t16dUqJlGNLWss3KiI/Q81f3U/ukaL/mJdgBAAAE2KS31qhdYpRe/9vJio8KlyRV1jbo5lcLNGnBGj3/5/5+zcvjTgAAAALsqy0VGn92N0+ok6SE6HDdeWY3fbW1wu95CXYAAAABFm4NUa3T1ax9X4NLYaH+xzOCHQAAQICd0S1V4+ev1srtlTIMQ4Zh6Nvtlbr79e815Pg0v+flGjsAAIAAm/iHXN06d5UumL5MYSH799lcbreGHJ+miX/I8Xtegh0AAECAxUWG6bmRfbW1rFabS2pkSMpOjVGHZP/uhv0JwQ4AACBIOiZHq+MRhrn/RbADAAAIgPvfLtStw7oqKtyq+98uPGjfe8/173QswQ4AACAA1uzcq8Ymw/Pz0UCwAwAACIA515/k8+eWxONOAAAAAuz211ap5gDPsbv9tVV+z0uwAwAACLB53+5QfWNTs/b6Rrfmryz2e15OxQIAAASIo75RhiRDUq3TJZv15z02t1v6dF2JkqLDDzj+1xDsAAAAAqTnfR/KIski6fSHP2t23GKx6JYh2X7PT7ADAAAIkP/+5XcyDOmy577U9Mv7KD4qzHMsLDREmQmRSouN8Ht+gh0AAECA/K5TkiRp8R2nq218pCwWS4vOz80TAAAAAbZsc7neXb27Wfs73+3S/32zw+95CXYAAAAB9sxnm5UQHdasPSkmXE9/usnveQl2AAAAAbajqk5ZCVHN2tvGR6q4qs7veQl2AAAAAZYcHa51ux3N2tfuqlZCFI87AQAAaDWG92qjSQvWKNoWqhM77r+h4qst5brvrUIN75Xh97wEOwAAgAC7ddhx2lFVp8uf+0rWkP13xroN6YK8trr99938npdgBwAAEGDh1hA9ddkJ2lJao7W7HIoIC9Fx6XZl+rju7nAQ7AAAAIKkU0qMOqXEtNh8BDsAAIAAuP/tQt06rKuiwq26/+3Cg/a999wcv34HwQ4AACAA1uzcq8Ymw/PzgVjk/7dREOwAAAACYM71J/n8uSXxHDsAAACTYMcOAAAgAEa99PUh9332yr5+/Q527AAAAALAHhHmecXYwrRsU7lW7/j5Wrvvi6u1bFO57BHNv0P2ULFjBwAAEAAPX9zL83P+e2t1Ts8MPfjHHgr98QHFTW5D97zxvewR/sczduwAAAAC7LWvd+gvp3TyhDpJCg2x6LpBHTX36yK/5yXYAQAABJirya1NJTXN2jeV1MjtNvyel1OxAAAAAXZx3yzd8X/faVt5rfLaJUiSVm6v1PTPNuvivll+z0uwAwAACLC7zz5eKXabZi7ZqhLHOklSqt2mUad21l8GdfJ7Xr+CXeOuXZLForD0dElS3Xffae/bb8vWuYsS/nSJ38UAAAAcC0JCLLrh1M664dTOctQ3StIR3Q3rmdefQcW33a59X30lSXKVlmr7Ndeq/rvVKn3sMZU+9dQRFwUAAGB2ria3lmws04JVO2Wx7L+JYk91vWqdLr/n9GvHzrlxoyJ69JQkVb/3vmzZ2erw39mqWbJUuydNUsro0X4XBAAAYHY7Kvdp5Kzl2llVr4YmtwZ1SVGMzapnFm2W0+XWlD/28Gtev3bsDJdLlvBwSVLtF18oZvDpkiRbp45ylZb6VQgAAMCx4r63CtUzM16rJg5ThPXnOPb73HQt21Tm97x+BTtbly6qenWO9n39tWqXLVPMoEGSJFdJiULj4/0uBgAA4Fjw9Q8VGjO4i8Kt3lGsbXykdlfX+z2vX8Eu9dZbVfnqXG27aqRizzlHEd26SZIcn3yqyJ7+bR0CAAAcK9yGfD6vbnd1vWJs/j+0xK+R0Sf2V9cvlsldU6PQuDhPe/wllygkMsLvYgAAAI4FA7OTNWvpVuVfsP+eBYtFqnW69NhHG3Tacal+z+tXsHPX10uG4Ql1jcXFcnz8scI7dVbMoIF+FwMAAHAsuPecHF327y815NFFcrrcumnOSv1QVquE6HD969I8v+f1K9jt+Nto2YcNVcKIEWqqrtbWP42QxWpVU2Wl0u66UwmXXup3Qb+mYvZsVcycJVdpqWxduihtwnhF9e17wP61y5erZOo0OTdtkjU1VUnXXauEESO8+lR/8KFK//UvNW7frrB27ZRy81jFDh161NYAAACO3Etf/KBnP9+iEodTXdNi9Pdzc9W/Y+IB+3+5pVwPvFOoDXtqlBZr06hTOuuK37X36vPe6l165KMN2l6+T+2SonTbsON0Zvf0Fq89PS5C744dpAWrdur74r1yG4b+1DdL5+e1VURYqN/z+nWNXX1hoaL69JEkVX/wgaxJSeryyUK1mTZVFS+97Hcxv6b63Xe1J3+qkm4YpY6vz1dk3z7afv0oNe7c6bN/w44dKhp1gyL79lHH1+cradT12v3gFFV/8KGnz76VK1U8bpzi/vAHdXzzDcX94Q8qvmWc6latOmrrAAAAR+atVTs1+e1CjTm9i969aaD6dUjU1c8vV3FVnc/+RRX79OfnV6hfh0S9e9NAjT6ti+57a43eW73L0+ebbZUa89+V+mNeW707dpD+mNdWY2Z/q5XbK1u09sYmtwY99ImKKvbpkr5Zmnxedz1wfg+N6N/uiEKddASnYkOioyVJtUuXyT50qCwhIYrs1euAIasllL/wH8VfeIESLr5YkpQ+YYJqlyxV5X/nKPXWcc36V82Zo7CMDKVPmCBJsnXurPrv16hi1izF/n6YJKnixRcVffLJSh51/f4+o67XvhUrVPGfF9X20UeO2loOxu12a191bVB+NwAAhyIqNlohIX7tD7WI55Zs1SV9szSifztJ0sThufp8Q6le/nKb7jyzW7P+L3+1TW3iIzRxeK4kqUuqXd8V79WMxVt0Vo8MSdKspVs1sEuyRp/e5cc+XfTV1grNWvqDnvjx+1xbQlhoiBpcbv34TOIW5VewC2/XTo6PF8o+dIhqlyxR4sirJEmu8gqFxMS0aIE/MRoaVL9mjZL+cp1Xe/SAAapbudLnmH0FBYoeMMC7/8ABqpo3T0ZjoyxhYaorWOWp/3/7VLz44gFrcTqdcjqdnvcOh+Nwl3NQ+6pr1X3q5y06JwAALen7u05RTLy9Red0OByqrq72vLfZbLLZbM36Nbjc+r54r/56amev9kHZKfpmm+/dtZXbqjQoO8Wr7ZTsFM1dUaTGJrfCQkO0clulrhnY8Rd9kvX80h/8XNGBjTy5g6Z/tkXTLuwha2jLBWS/gl3y3/6m4ttv156pUxX9uxMVlbf/Ir/apUsVcfzxLVbc/3JVVklNTbImJXu1W5OSVFvm+0F+TaVlsg5M+kX/ZMnlkquyUmGpqXKVlfmYM1lNpQd+OGB+fr7uu+8+/xYCAAB8ysnJ8Xo/ceJETZo0qVm/yn0NanIbSrGHe7Wn2G0q2+Bs1l+SSmucSrHbftE/XC63ocraBqXGRhygj02lDt9zHomC7VVatrlcizeW6rh0u6LCvU/BPnvlge8fOBi/gl3smb9XVJ8T9t/A0O3n7c7ok34n+9AhfhVyyJptWxo66F5ms2PGj82Wg/c5yJzjx4/XuHE/n/otLi5u9o/xSETFRuv7u05psfkAAGhpUbHRLT5nYWGh2rZt63nva7fOm/dntWEYPnLCgRk/PUbuIGMM4+DH/RUbGXZUbsrw+wl41pQUWVNS1Lh7t2SxKCwtTZE9e7Zkbd6/LyFeCg2V6xe7c67yClmTknyOCU1J9tG/XLJaPd+QYU1OlqustFmf0GTfc0rNt4b/d9u4JYSEhLT49jYAAL91drtdsbGxv9ovISpcoSGWZjtpZTUNSo7xHQZTYprvvJXVNMgaYlFCVPhB+jiVcoA5j8TDF/dq8Tklf78r1u1W6VNPaX3ffto0+AxtOn2w1vfrr9Knn5bhdrd0jZIkS3i4InJzVbtsmVd77bJliszz/byXqN69m/dfulSRubmyhIVJkiJ79/LRZ5mievv/DBkAAHD0hFtD1L1tnJZs8t6YWbKpTH3a+77JIa99vJb84jtYF28sVY/MOIX9eI1bXvsEH33KdMIB5mwJZTVOLd9aoRU/VKis5shP+fq1Y1f62D9VNW+eUm8dp8gTTpAMQ/u+/VZlTz4lw9mg1FtuPuLCfEm6eqSK77xLkd27K7J3b1XNnavGXbuUMOJPkqSSRx6Vq2SP2kybJkmKHzFCFa/M1p78qYq/5GLVFRSoat58tX34Yc+ciVdepW1XXqmyf/9b9jPOkGPhQtV+8YU6vHL0HtsCAACOzHUDO2rc3AL1bBuvE9rHa/ZXRdpZVafLT9x/l+y099dpz956Pfqn3pKkK05srxeXbdP9bxfq0v5Z+nZbleZ+XaR/jfh5I+eaAR10ybNfavpnmzU0J00fFe7R0k1leu2Gk1q8fkd9o/7+5hq9tWqnmn48JxxqsejcnhmafH53xUaE+TWvX8Fu7xtvKOOB+2UfPNjTFtGtm8LS0rT7vslHLdjFnn22XFVVKnvq6f3X92Vnq92zzyjsx/PxrtJSNe78+Xk04ZmZynr2Ge2ZOlWVs2fLmpqq9LsneB51IklRJ+Sp7SOPqPTxx1X6rycUnpWlto8+osheR2eLFAAAHLnhvdqoal+DHl+4UaUOp7qmx+j5q/spMyFKklRS7fR6pl1WYpSe/3M/3f92oV76YptSY22aODzX86gTSerTPlFPXJqnhz9cr0c/Wq92iVF68rI85bXgo05+cte81SrcVa2ZV/fTCe3iZbFY9M22St331hqNn7daT11+gl/zWgzDaP4NtL9iXc9e6vjmG7J19L4l2Lllq7b+8Y/qtqrAr2Jaqx07digrK0tFRUXKzMwMdjkAALQqx+Ln6PH3vq8Xr+2vfh28vylj+dYKjZy1XGvvP9Ovef26xs7WrZsqX5ndrL3ylVdkO+44vwoBAAA4ViREhcke0fzEqT3CqrhI/07DSn6eik297VYV3fBX1X7xhSJ795IsFtWtLJBr1y5lzXjW72IAAACOBWMGZ+uBt9fq0Ut6KTU2QpJU4qjXlHfX6sYzuvg9r1/BLrp/f3V+7z1Vzp6thi1bJBmyDx2ihEsuUemTTymqr38P1QMAADgWvPzlNm0rr9WAaZ+oTXykJGlnVZ3CQ0NUUdug2V9t9/R956ZBhzyv38+xC0tLbXaTRP26ddr7xhtqM+VBf6cFAAAwvWG5aUdlXr+DHQAAAPxz85CuR2XelvvWWQAAAAQVwQ4AAMAkDutU7I4bbzzo8aZqxxEVAwAAAP8dVrALiTn4F9OHxNgVd955R1QQAAAA/HNYwa5N/pSjVQcAAMAx4/GPN+r6UzopMjzUq72+sUnPLtqisUOy/ZqXa+wAAAAC7PGFG1Tb4GrWXtfQpMcXbvB7XoIdAABAgBmSLD7a1+6qVnxUuN/z8hw7AACAAOk56QNZLBZZJJ3+8GeyWH6Od263odoGly4/sb3f8xPsAAAAAuTvw3NlGIbumPedbhnaVfaIMM+xsFCLMhOi1Kd9gt/zE+wAAAAC5KI+mZKkrMQo9W2fIGtoy14VxzV2AAAAAVbX0KSlm8ubtS/aUKpP15f4PS/BDgAAIMCmvb9ObrfRrN0wDE17b53f8xLsAAAAAmxrWa26pMY0a++cEqNt5fv8npdgBwAAEGD2iDAVVTQPcNvK9ynqFw8tPhwEOwAAgAAbmpOqyW8Xalt5rafth7JaPfBOoYYcn+b3vNwVCwAAEGDjzz5eI2ct1xmPLFJ6XIQkaffeevXrkKgJ5xzv97wEOwAAgACLjQjT/L+erMUby7R2V7UiwkLVLd2uEzslHdG8BDsAAIAgsFgsOqVrivp3TJTNGuL1LRT+4ho7AACAAHO7Df1r4UadOOVj5U78QEUVdZKkRz5cr1dXbPd7XoIdAABAgD3xySb93zc7NP6s4xUW+vNO3XHpds1ZUeT3vAQ7AACAAJu/cofyL+ih8/PaKvR/TsF2S4/V5pIav+cl2AEAAATY7r31ap8U1azdMAy5fHwjxaEi2AEAAARY1zS7VvxQ0az9ndW7lNsm1u95uSsWAAAgwMaeka1b5hZo916n3Ib0/ppd2lJaq/nfFmvm1X39npcdOwAAgAAbkpOmJy87QZ+uL5HFIj360QZtKqnRcyP7alB2it/zsmMHAAAQQK4mt578dJMu6ZuluaNOatG52bEDAAAIIGtoiGZ8vkVNR3CTxIEQ7AAAAAJsQJdkfbmlvMXn5VQsAABAgJ12XIoe+mC9NuxxqHvbOEWFe0eyoTlpfs1LsAMAAAiwe974XpL03JKtzY5ZJG3JP8eveQl2AAAAAbbVz+D2a7jGDgAAIIBcTW51nvCu1u92tPjcBDsAAIAAsoaGqG18JHfFAgAAmMGYwV300AfrVLWvoUXn5Ro7AACAAHth6Q/aVl6r/lMWKjM+UpHhoV7H37lpkF/zEuwAAAACbFiuf48z+TUEOwAAgAC7eUjXozIvwQ4AACBIVu/Yq02lDllkUZfUGHVvG3dE8xHsAAAAAqysxqkbZ6/Ul1vLFRsRJsMw5HC6dFKnJD1xaZ6SYmx+zUuwAwAACLCJC9aoxunSR7ecoi6pdknSxj0O3fraKk16q1BPXJrn17w87gQAACDAPl9fqgfO7+4JdZKUnWbX5PO667P1JX7PS7ADAAAIMLdhyBpqadZuDbHIOILnFhPsAAAAAuykzsm6761C7amu97Tt3luv+98u1Mmdk/yel2vsAAAAAmzyebn6y4tfa+C0T5QRFymLRdpZVafj0u3654jefs9LsAMAAAiwNvGReuemQVq8sVSbS2pkSMpOtWtgdvIRzUuwAwAACJJB2SkalJ3SYvNxjR0AAECALNtUpiGPLpKjvrHZser6Rg19dJGWb63we36CHQAAQIDMWrpVI/plyR4R1uxYbESYLjuxnZ5bvMXv+Ql2AAAAAbJ2l0OnHXfgU6+DslP0ffFev+cn2AEAAARIaY1T1pADxy9riEXltQ1+z0+wAwAACJD02Ait2+044PF1u6uVGuvf98RKBDsAAICAOf24FD320QbVNzY1O1bf2KTHPtqoM7ql+T0/jzsBAAAIkDGDs/X+msUa/PBnuurkDuqUHC2LxaJNJTV66Ysf1GQYGn16F7/nJ9gBAAAESIrdpnl/PVn3vPG9Hnp/nX76WliLpFO6puj+87orxe7/qViCHQAAQABlJkTphT/31959jfqhvFaGpI5J0YqLav4IlMNFsAMAAAiCuKgw9YqKb9E5uXkCAADAJAh2AAAAJtFqTsU27d2r3Q8+qJpPPpUkxQw+Xen33KPQ2NgDjjEMQ2VPPqWquXPVVF2tyJ49lf73e2XLzt4/Z1WVSp94UrVLl6px926FJiTIfsYZShl7k0Lt9oCsCwAAHD179zVq0ltr9HHhHknSkJw0TfpDruIiD3w9m2EY+ufHG/Xf5du1t65RvbPidf/53dU1bX82qNrXoMc+2qDFG8u0c2+dEqPCNSw3XeOGdVWsj68KC6RWs2NXfNvtcq5dp6x/z1DWv2fIuXaddt5x50HHlD/3nCpeeEFp996jDq/NlTUlWduvuVZNNbWSpMaSErlKSpR6xx3qtOBNtcmfotrFi7Xr7nsCsSQAAHCU3TRnpQp3VuuFa/rrhWv6q3Bntca9WnDQMc8s2qKZS7Zq8nm5WjBmoFLsNl3x3FeqcbokSXuqndpT7dSEs4/XBzefoocv7qVFG0p15/99F4AVHVyrCHbOzZtVu3ixMh64X1F5eYrKy1PG/ZNV89lncm7Z6nOMYRiqePFFJd0wSrHDhimia1dlTJ0qd329qt9+W5IU0bWrMp/4l+yDT1d4u3aK/t3vlHLLzar59FMZLlcglwgAAFrYphKHFm0o1dQLe6hP+wT1aZ+g/At7aOG6Em0urfE5xjAMzVq6VaNP76Izu2fouHS7Hrmkl+oam/RmQbEk6bh0u565so+G5KSpfVK0Tu6SrNuGHaeFa0vkanIHconNtIpgV1dQoBC7XZG9ennaInv3VojdrrqVK32OadyxQ02lZYoZMMDTFhIerqh+/Q44RpKaHA6FxMTIYj3wWWqn06nq6mrPy+E48FeDAACAQ+NwOLw+X51O5xHN9+22KtkjrMprl+BpO6FdguwRVn2zrdLnmKKKOpU6nBqUnexps1lDdWLHpAOOkSRHfaNiIqyyhgY3WrWKYOcqLZM1MbFZuzUxUa6ysgOOkaTQpGSvdmtS0oHHVFaqbPp0xf/pkoPWk5+fr7i4OM8rJyfnUJYBAAAOIicnx+vzNT8//4jmK61xKjmm+cN+k2NsKnX4Do2lNfWS1OwhwSn28AOOqaxt0BOfbNJl/dsdUb0tIag3T5Q+8aTKnnrqoH06vPba/h8slmbHDBk+2700O+x7TFNNjYpuuEG2zl2UMnr0QaccP368xo0b53lfXFxMuAMA4AgVFhaqbdu2nvc2m+9vYHjsow16fOHGg861YMz+M3a+UoJhGIcdHwxDsvgY5Khv1J9fWKEuqTEaOyT74JMGQFCDXcIVlyv2nLMP2iesbVs5N6yXq7y82bGmikpZk5J8jrOm7N+payorU1hqqqfdVV7RbExTTa2KrvuLQqKilPnkE7KEHfyOFpvN5vWPrbq6+qD9AQDAr7Pb7Yo9yNMufjLy5A4a3qvNQftkJkRq3S6HSmua77KV1zb43MmTpJSYCElSicOp1NgIT3tZTYOSY8K9+tY4XRo5a7mibaF69so+CgvyaVgpyMHOmpAga0LCr/aL7N1bbodDdd99p8iePSVJdatWye1wKDIvz+eYsMxMhaYkq3bZMkX8uJtmNDRo34oVSr31Vk+/ppoaFV17nSzh4cp6+mmFHOD/HQAAgN+GxOhwJUaH/2q/E9rHy1HvUkFRlXpnxUuSVm6vlKPepT7tfeePrMRIpdhtWrKpTN3bxkmSGlxufbW1XHed1c3Tz1HfqKtmLVd4aIieu6qfIsJCj3xhLSD40fIQ2Dp3VvSgQdp1799VV1CguoIC7br374o57TTZOnX09Nt81tmq/ugjSfu3SxOvukplz85Q9UcfqX7DBu0cP0EhERGKPfdcSft36rZfe63cdXXKePABuWtq5Cotlau0VEZTU1DWCgAAWkaXVLtO7Zqiu+Z9p2+3V+rb7ZUaP3+1zuiWqs4pMZ5+gx/5TO9/v1vS/vxwzYCOeurTTXr/+91av9uh215bpciwUJ3Xe/9p4hqnS1fOXK66hiY9dFFPOZyNKnHUq8RRrya3EZS1/qTVPKC47T8e0u4Hp2j7tddJkmIGD1b6vd7Pm2vYulVux8+3Lyddd52Meqd2T54s9979DyjOmvmcQmOiJUn1a9aoftX+Z85sHvZ7r7k6f/yxwjPbCgAAtF6Pj+itSQvW6KqZyyVJQ45P1X3ndffqs6W0Vo76Rs/7G07tpPrGJt375veeBxS/dO2JirHtj02rd+xVQVGVJOnUf3zmNdfiO05XVmLU0VvQr7AYhhHcaGkCO3bsUFZWloqKipSZmRnscgAAaFX4HG05reJULAAAAH4dwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBKtJtg17d2r4jvu0Pq+/bS+bz8V33GHmqqrDzrGMAyVPvGkNg46Ret69da2K6+Sc+PGA/bd/pfrtbbb8XJ8/PHRWAIAAAiwvfsadcurBeox8QP1mPiBbnm1QHvrGg86xjAMPfbRBvV/8GMdd897+tOzX2jDHscB+46ctVwd7npHH6zZfTSWcFhaTbArvu12OdeuU9a/Zyjr3zPkXLtOO++486Bjyp97ThUvvKC0e+9Rh9fmypqSrO3XXKummtpmfSv+8x/JcrSqBwAAwXDTnJUq3FmtF67prxeu6a/CndUa92rBQcc8s2iLZi7Zqsnn5WrBmIFKsdt0xXNfqcbpatZ35pKtsvyG8kOrCHbOzZtVu3ixMh64X1F5eYrKy1PG/ZNV89lncm7Z6nOMYRiqePFFJd0wSrHDhimia1dlTJ0qd329qt9+26tv/bp1qnjhP2rz4IOBWA4AAAiATSUOLdpQqqkX9lCf9gnq0z5B+Rf20MJ1JdpcWuNzjGEYmrV0q0af3kVnds/Qcel2PXJJL9U1NunNgmKvvoU7qzVzyVY9dFHPQCznkLSKYFdXUKAQu12RvXp52iJ791aI3a66lSt9jmncsUNNpWWKGTDA0xYSHq6ofv28xrjr6lR8621Kv/ceWVNSDqkep9Op6upqz8vh8L09CwAADp3D4fD6fHU6nUc037fbqmSPsCqvXYKn7YR2CbJHWPXNtkqfY4oq6lTqcGpQdrKnzWYN1Ykdk7zG1DU06aY5K3XfH3KVao84ojpbUqsIdq7SMlkTE5u1WxMT5SorO+AYSQpNSvZqtyYleY3Zkz9VkXm9ZT/jjEOuJz8/X3FxcZ5XTk7OIY8FAAC+5eTkeH2+5ufnH9F8pTVOJcfYmrUnx9hU6vAdGktr6iVJKXbvcSn2cK8xk98uVJ92CRqWm35ENbY0azB/eekTT6rsqacO2qfDa6/t/8HHCWxDhs92L80O/zzG8cknqv3qS3WaP/8QK95v/PjxGjdunOd9cXEx4Q4AgCNUWFiotm3bet7bbM1DmSQ99tEGPb7Q982QP1kwZv8ZO18pwTCMw44PhiFZfhz0UeEefbG5TO/cNOjgkwRBUINdwhWXK/acsw/aJ6xtWzk3rJervLzZsaaKSlmTknyOs6bs36lrKitTWGqqp91VXuEZU/vll2rcXqT1/U/0GrvjprGK6tNH7V960efcNpvN6x9b9a/cnQsAAH6d3W5XbGzsr/YbeXIHDe/V5qB9MhMitW6XQ6U1zXfmymsbfO7kSVJKzP7TqiUOp1Jjfz7FWlbToOSYcEnSss1l2laxTz3v+9Br7F9f/kb9OiTq1VEn/eoajpagBjtrQoKsCQm/2i+yd2+5HQ7VffedInvuv0CxbtUquR0ORebl+RwTlpmp0JRk1S5bpogfd9OMhgbtW7FCqbfeKklK/stfFH/RRV7jtv7hPKXddZdiBp9+JEsDAABHSWJ0uBKjw3+13wnt4+Wod6mgqEq9s+IlSSu3V8pR71Kf9r7zR1ZipFLsNi3ZVKbubeMkSQ0ut77aWq67zuomSfrraZ01ol87r3G//+fnuvfcHA05Pu0IVnbkghrsDpWtc2dFDxqkXff+XRn3TZIk7fr7RMWcdppsnTp6+m0+62yljLtFsUOHymKxKPGqq1T27AyFtW+v8PbtVf7sDIVERCj23HMlSdaUFJ83TIS1yVB4ZmZA1gYAAI6OLql2ndo1RXfN+05TLughSZowf7XO6Jaqzikxnn6DH/lMd/y+m87sni6LxaJrBnTUU59uUoekaHVMjtZTn25SZFiozuu9/zRxqj3C5w0TbeIjlZUYFZjFHUCrCHaS1PYfD2n3g1O0/drrJEkxgwcr/d57vPo0bN0qt+Pn25eTrrtORr1TuydPlntvtSJ79lTWzOcUGhMd0NoBAEBwPD6ityYtWKOrZi6XJA05PlX3ndfdq8+W0lo56n9+aPENp3ZSfWOT7n3ze+2ta1TvrHi9dO2JirH99mOTxTAMI9hFtHY7duxQVlaWioqKlMlOHwAAh4XP0ZbTKh53AgAAgF9HsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCSswS7ADNxutyRp165dQa4EAIDW56fPz58+T+E/gl0L2LNnjySpf//+Qa4EAIDWa8+ePWrXrl2wy2jVLIZhGMEuorVzuVxauXKl0tLSFBLC2W2Hw6GcnBwVFhbKbrcHu5xjBn/34OFvHxz83YPjaPzd3W639uzZo7y8PFmt7DkdCYIdWlx1dbXi4uK0d+9excbGBrucYwZ/9+Dhbx8c/N2Dg7/7bxvbSwAAACZBsAMAADAJgh1anM1m08SJE2Wz2YJdyjGFv3vw8LcPDv7uwcHf/beNa+wAAABMgh07AAAAkyDYAQAAmATBDgAAwCQIdmgx+fn56tevn+x2u1JTU3X++edr/fr1wS7rmJOfny+LxaKbb7452KWYXnFxsa644golJSUpKipKvXv31jfffBPsskzN5XLpnnvuUceOHRUZGalOnTpp8uTJfBXVUfD5559r+PDhatOmjSwWi9544w2v44ZhaNKkSWrTpo0iIyN12mmnac2aNcEpFh4EO7SYRYsWafTo0fryyy/10UcfyeVyadiwYaqtrQ12aceMFStWaMaMGerZs2ewSzG9yspKDRgwQGFhYXrvvfdUWFioRx55RPHx8cEuzdSmTZumZ555Rk8++aTWrl2rhx56SP/4xz/0xBNPBLs006mtrVWvXr305JNP+jz+0EMP6dFHH9WTTz6pFStWKD09XUOHDpXD4Qhwpfhf3BWLo6a0tFSpqalatGiRTjnllGCXY3o1NTU64YQT9PTTT+uBBx5Q79699c9//jPYZZnWXXfdpaVLl2rx4sXBLuWYcu655yotLU0zZ870tF144YWKiorSSy+9FMTKzM1isej111/X+eefL2n/bl2bNm108803684775QkOZ1OpaWladq0aRo1alQQqz22sWOHo2bv3r2SpMTExCBXcmwYPXq0zjnnHA0ZMiTYpRwTFixYoL59++riiy9Wamqq8vLy9O9//zvYZZnewIEDtXDhQm3YsEGStGrVKi1ZskRnn312kCs7tmzdulW7d+/WsGHDPG02m02nnnqqli1bFsTKwDft4qgwDEPjxo3TwIED1b1792CXY3pz5szRt99+qxUrVgS7lGPGli1bNH36dI0bN04TJkzQ8uXLddNNN8lms+mqq64Kdnmmdeedd2rv3r3q1q2bQkND1dTUpAcffFCXXnppsEs7puzevVuSlJaW5tWelpambdu2BaMk/Ihgh6NizJgx+u6777RkyZJgl2J6RUVFGjt2rD788ENFREQEu5xjhtvtVt++fTVlyhRJUl5entasWaPp06cT7I6iV199VS+//LJmz56t3NxcFRQU6Oabb1abNm00cuTIYJd3zLFYLF7vDcNo1obAItihxd14441asGCBPv/8c2VmZga7HNP75ptvVFJSoj59+njampqa9Pnnn+vJJ5+U0+lUaGhoECs0p4yMDOXk5Hi1HX/88Zo3b16QKjo23H777brrrrs0YsQISVKPHj20bds25efnE+wCKD09XdL+nbuMjAxPe0lJSbNdPAQW19ihxRiGoTFjxmj+/Pn65JNP1LFjx2CXdEw444wztHr1ahUUFHheffv21eWXX66CggJC3VEyYMCAZo/z2bBhg9q3bx+kio4N+/btU0iI90dXaGgojzsJsI4dOyo9PV0fffSRp62hoUGLFi3SySefHMTKwI4dWszo0aM1e/Zsvfnmm7Lb7Z5rMOLi4hQZGRnk6szLbrc3u44xOjpaSUlJXN94FN1yyy06+eSTNWXKFF1yySVavny5ZsyYoRkzZgS7NFMbPny4HnzwQbVr1065ublauXKlHn30UV1zzTXBLs10ampqtGnTJs/7rVu3qqCgQImJiWrXrp1uvvlmTZkyRdnZ2crOztaUKVMUFRWlyy67LIhVQwbQQiT5fD3//PPBLu2Yc+qppxpjx44Ndhmm99Zbbxndu3c3bDab0a1bN2PGjBnBLsn0qqurjbFjxxrt2rUzIiIijE6dOhl333234XQ6g12a6Xz66ac+/zd95MiRhmEYhtvtNiZOnGikp6cbNpvNOOWUU4zVq1cHt2gYPMcOAADAJLjGDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAOwGKx6I033gh2GQBwyAh2AH6Trr76alkslmavM888M9ilAcBvljXYBQDAgZx55pl6/vnnvdpsNluQqgGA3z527AD8ZtlsNqWnp3u9EhISJO0/TTp9+nSdddZZioyMVMeOHfXaa695jV+9erUGDx6syMhIJSUl6frrr1dNTY1Xn1mzZik3N1c2m00ZGRkaM2aM1/GysjL98Y9/VFRUlLKzs7VgwYKju2gAOAIEOwCt1r333qsLL7xQq1at0hVXXKFLL71Ua9eulSTt27dPZ555phISErRixQq99tpr+vjjj72C2/Tp0zV69Ghdf/31Wr16tRYsWKAuXbp4/Y777rtPl1xyib777judffbZuvzyy1VRURHQdQLAITMA4Ddo5MiRRmhoqBEdHe31mjx5smEYhiHJuOGGG7zGnHjiicZf//pXwzAMY8aMGUZCQoJRU1PjOf7OO+8YISEhxu7duw3DMIw2bdoYd9999wFrkGTcc889nvc1NTWGxWIx3nvvvRZbJwC0JK6xA/Cbdfrpp2v69OlebYmJiZ6fTzrpJK9jJ510kgoKCiRJa9euVa9evRQdHe05PmDAALndbq1fv14Wi0U7d+7UGWeccdAaevbs6fk5OjpadrtdJSUl/i4JAI4qgh2A36zo6Ohmp0Z/jcVikSQZhuH52VefyMjIQ5ovLCys2Vi3231YNQFAoHCNHYBW68svv2z2vlu3bpKknJwcFRQUqLa21nN86dKlCgkJUdeuXWW329WhQwctXLgwoDUDwNHEjh2A3yyn06ndu3d7tVmtViUnJ0uSXnvtNfXt21cDBw7UK6+8ouXLl2vmzJmSpMsvv1wTJ07UyJEjNWnSJJWWlurGG2/UlVdeqbS0NEnSpEmTdMMNNyg1NVVnnXWWHA6Hli5dqhtvvDGwCwWAFkKwA/Cb9f777ysjI8Or7bjjjtO6desk7b9jdc6cOfrb3/6m9PR0vfLKK8rJyZEkRUVF6YMPPtDYsWPVr18/RUVF6cILL9Sjjz7qmWvkyJGqr6/XY489pttuu03Jycm66KKLArdAAGhhFsMwjGAXAQCHy2Kx6PXXX9f5558f7FIA4DeDa+wAAABMgmAHAABgElxjB6BV4ioSAGiOHTsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACT+H+L9pT2lLly6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "ax1.plot(np.arange(1, 11), loss, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Correct predictions', color=color)\n",
    "ax2.plot(np.arange(1, 11), accuracy, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1bb5eaf04ee616cb97a7646d642cbb4883a22e93827c7cd2dfad8795f88fc9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
