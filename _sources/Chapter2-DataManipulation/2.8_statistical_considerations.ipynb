{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.8 Statistical Considerations for geoscientific Data and Noise\n",
    "\n",
    "Statistical properties of geoscientific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules for seismic data and feature extraction\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import scipy.signal as sig\n",
    "\n",
    "# time series feature extraction python toolbox:\n",
    "# import tsfresh\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Statistical Features\n",
    "\n",
    "::warning:: this might be replaced with slides.\n",
    "\n",
    "s\n",
    "Let be $P(z)$ the distribution of the data $z$.\n",
    "\n",
    "### The mean\n",
    "<div>\n",
    "<img src=\"mean.png\" alt=\"mean\" height=300  />\n",
    "</div>\n",
    "\n",
    "Image taken from this [blog](!https://gregorygundersen.com/blog/2020/04/11/moments).\n",
    "\n",
    "The mean is the sum of the values divided by the number of data points. It is the first raw moment of a distribution. \n",
    "$\\mu = \\int_{-\\infty}^\\infty zP(z)dz$, where z is the ground motion value (bin) and $P(z)$ is the distribution of the data.\n",
    "\n",
    "### The Variance\n",
    " <div>\n",
    "<img src=\"variance.png\" alt=\"variance\" height=200  />\n",
    "</div>\n",
    "\n",
    "The variance is the second *centralized* moment. *Centralized* means that the distribution is shifted around the mean. It calculates how spread out is a distribution.\n",
    "\n",
    "$\\sigma^2 = \\int_{-\\infty}^\\infty (z-\\mu)^2P(z)dz$\n",
    "\n",
    "The standard deviation is the square root of the variance, $\\sigma$. A high variance indicates a wide distribution.\n",
    "\n",
    "### The skewness\n",
    "\n",
    "Skewness is the third *standardized* moment. The *standardized* moment is scaled by the standard deviation. It measures the relative size of the two tails of the distribution.\n",
    "\n",
    "\n",
    "$m_3= \\int_{-\\infty}^\\infty \\frac{(z - \\mu)^3}{\\sigma^3}P(z)dz$\n",
    "\n",
    "With the cubic exponent, it is possible that the skewness is negative.\n",
    "\n",
    " <div>\n",
    "<img src=\"skewness.png\" alt=\"skewness\" height=200  />\n",
    "</div>\n",
    "\n",
    "Image taken from this [blog](!https://gregorygundersen.com/blog/2020/04/11/moments).\n",
    "\n",
    "A positively skewed distribution is one where most of the weight is at the end of the distribution. A negatively skewed distribution is one where most of the weight is at the beginning of the distribution.\n",
    "\n",
    "\n",
    "### Kurtosis\n",
    "\n",
    "Kurtosis measures the combined size of the two tails relative to the whole distribution. It is the fourth centralized and standardized moment.\n",
    "\n",
    "$m_4= \\int_{-\\infty}^\\infty (\\frac{z-\\mu}{\\sigma})^4P(z)dz$\n",
    "\n",
    " <div>\n",
    "<img src=\"kurtosis.png\" alt=\"kurtosis\" height=200  />\n",
    "</div>\n",
    "The laplace, normal, and uniform distributions have a mean of 0 and a variance of 1. But their kurtosis is 3, 0, and -1.2.\n",
    "\n",
    "\n",
    "Python functions to calculate the moments might be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_moment(X, k, c=0):\n",
    "    return ((X - c)**k).mean()\n",
    "\n",
    "def central_moment(X, k):\n",
    "    return raw_moment(X=X, k=k, c=X.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Toy problem: synthetic data and noise\n",
    "\n",
    "\n",
    "Here we will construct a time series with 1 ricker wavelet as a source and synthetic noise\n",
    "\n",
    "We will analyze their statistical properties and compare the distributions. Present this as a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100. # sampling rate\n",
    "twin = 50. # window length\n",
    "t = np.linspace(0,twin,int(twin*fs)) #points = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Signal\n",
    "\n",
    "We will create an event signal as a Ricker wavelet of specified width, 4 seconds in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 50 # proportional to the width of the wavelet, about a factor of 10\n",
    "sa = sig.ricker(int(a*fs), a)\n",
    "# plate the signal in the middle of the time series\n",
    "s = np.concatenate((np.zeros(len(t)//2-len(sa)//2),sa,np.zeros(len(t)//2-len(sa)//2)))\n",
    "\n",
    "# plot the signal\n",
    "plt.plot(t,s)\n",
    "plt.xlabel('Time in s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ricker wavelet is a smooth function with a signal in a specific frequency band. Let's plot it's absolute Fourier amplitude spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, fftfreq, next_fast_len\n",
    "\n",
    "## FFT the signals\n",
    "# fill up until 2^N value to speed up the FFT\n",
    "Nfft = next_fast_len(len(s)) # this will be an even number\n",
    "\n",
    "freqVec = fftfreq(Nfft, d=1/fs)[:Nfft//2]\n",
    "Zhat = fft(s,n=Nfft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].plot(freqVec, np.abs(Zhat[:Nfft//2]))\n",
    "ax[0].grid()\n",
    "ax[0].set_title('FFT of the signal')\n",
    "ax[0].set_xlabel('Frequency in Hz')\n",
    "ax[1].plot(freqVec, np.abs(Zhat[:Nfft//2]))\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('Frequency in Hz')\n",
    "ax[1].set_title('FFT of the signal in log')\n",
    "ax[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the event data distribution looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sa,bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a pure signal not contaminated by noise. Let's create a *noise* time series to add on the *signal* time series.\n",
    "\n",
    "Synthetic noise may take several form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.rand(len(s))\n",
    "plt.plot(t,noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Fourier amplitude spectrum of the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhat = fft(noise,n=Nfft)\n",
    "plt.plot(freqVec, np.abs(nhat[:Nfft//2]))\n",
    "plt.plot(freqVec, np.abs(Zhat[:Nfft//2]))\n",
    "plt.xscale('log')\n",
    "plt.legend(['noise','signal'])\n",
    "plt.xlabel('Frequency in Hz')\n",
    "plt.ylim([0,100])   \n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, they look very different in the spectral domain!\n",
    "Let's add noise to the data and plot it.\n",
    "\n",
    "We will tune a signal to noise ratio to multiply the noise level relative to the signal level. We define this as the max absolute amplitude of the signal, divided by the max absolute amplitude of the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 100 # signal to noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now normalize both noise and signal amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s /= np.max(np.abs(s)) # normalize the signal\n",
    "noise /= np.max(np.abs(noise)) # normalize the noise    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_signal = s + noise/SNR\n",
    "plt.plot(t,noisy_signal)\n",
    "plt.grid()\n",
    "plt.title('Noisy signal')\n",
    "plt.xlabel('Time in s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise may have different frequency content, or *color*. We can construct a time series of noise based on its Fourier amplitude spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import ifft\n",
    "# random phase\n",
    "NN = 2*np.pi*np.random.uniform(-1,1,Nfft//2)-np.pi\n",
    "newnoiseF=np.zeros(Nfft,dtype=np.complex_)\n",
    "for i in range(Nfft//2):\n",
    "    newnoiseF[i] = np.exp(1j*NN[i])\n",
    "    newnoiseF[-i] = np.conj(newnoiseF[i])\n",
    "newnoiseF[0] = 0\n",
    "noise = ifft(newnoiseF).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise/=np.max(np.abs(noise)) # normalize the noise  \n",
    "plt.plot(t,noise)\n",
    "plt.title('Noise with random phase and white spectrum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the new noise and the signal (Ricker wavelet) and plot them in time and frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = s+noise/SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].plot(t,news)\n",
    "ax[0].set_title('Noisy signal')\n",
    "ax[0].set_xlabel('Time in s')\n",
    "ax[0].grid()\n",
    "ax[1].plot(freqVec, np.abs(fft(news,n=Nfft)[:Nfft//2]))\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel('Frequency in Hz')\n",
    "ax[1].set_title('FFT of the noisy signal in log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the data distribution between the pure signal, the noise signal, and the combined signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].hist(noise,bins=20);ax[0].grid()\n",
    "ax[0].hist(s,bins=20);\n",
    "ax[1].hist(news,bins=20);ax[1].grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can now calculate the mean, variance, skewness, and kurtosis of the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter answers here using the functions for the moment.\n",
    "# the mean:\n",
    "print(raw_moment(news,1))\n",
    "\n",
    "# the variance:\n",
    "print(central_moment(news,2))\n",
    "\n",
    "# the skewness\n",
    "print(central_moment(news,3)/central_moment(news,2)**(3/2))\n",
    "\n",
    "# the kurtosis\n",
    "print(central_moment(news,4)/central_moment(news,2)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the numpy and scipy modules to get these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the mean is %4.2f, the variance is %4.2f, the skewness is %4.2f, the kurtosis is %4.2f'\n",
    " %(np.mean(news),np.std(news)**2,scipy.stats.skew(news),scipy.stats.kurtosis(news,fisher=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values may mean nothing without some additional context. We can download seismic noise data to see if the earthquake waveforms are statistically different from the noise. For that, we will download the same length of data prior to the earthquake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geological data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .csv data into a pandas dataframe\n",
    "\n",
    "df = pd.read_csv('EarthRocGranites.csv')\n",
    "\n",
    "# Remove any rows that are empty\n",
    "df = df.dropna()\n",
    "\n",
    "# Let's print out this data frame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's visualize the histograms of silica and magnesium\n",
    "\n",
    "# Create a subplot with two histograms side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot the histograms for each column\n",
    "axes[0].hist(df['SIO2(WT%)'], bins=60, color='black')\n",
    "axes[0].set_xlabel('SiO$_2$, wt%')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xlim([40, 100])\n",
    "\n",
    "axes[1].hist(df['MGO(WT%)'], bins=100, color='black')\n",
    "axes[1].set_xlabel('MgO, wt%')\n",
    "axes[1].set_ylabel('Count')\n",
    "# Note these xlims -> the data largely [but not completely!] sit between 0 and 10 wt%\n",
    "axes[1].set_xlim([0, 10])\n",
    "\n",
    "# Add spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more plot: let's look at a scatter of SiO2 vs. MgO\n",
    "plt.scatter(df['SIO2(WT%)'], df['MGO(WT%)'], c='red', alpha=0.125)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0,100])\n",
    "ax.set_xlabel('SiO$_2$, wt%')\n",
    "ax.set_ylim([0,100])\n",
    "ax.set_ylabel('MgO, wt%')\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate *moments* for SiO$_2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first define the moment functions\n",
    "\n",
    "def raw_moment(X, k, c=0):\n",
    "    return ((X - c)**k).mean()\n",
    "\n",
    "def central_moment(X, k):\n",
    "    return raw_moment(X=X, k=k, c=X.mean())\n",
    "\n",
    "# The mean:\n",
    "print(f'The mean is: {raw_moment(df[\"SIO2(WT%)\"], 1):4.2f}')\n",
    "\n",
    "# Variance:\n",
    "print(f'The variance is: {central_moment(df[\"SIO2(WT%)\"], 2):4.2f}')\n",
    "\n",
    "# Skewness:\n",
    "skewness = central_moment(df[\"SIO2(WT%)\"], 3) / central_moment(df[\"SIO2(WT%)\"], 2) ** (3/2)\n",
    "print(f'The skewness is: {skewness:4.2f}')\n",
    "\n",
    "# Kurtosis\n",
    "kurtosis_value = central_moment(df['SIO2(WT%)'], 4) / central_moment(df['SIO2(WT%)'], 2) ** 2\n",
    "print(f'The kurtosis is: {kurtosis_value:4.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also just use pandas (or numpy or scipy):\n",
    "\n",
    "print('The mean is: %4.2f, the variance is: %4.2f, the skewness is: %4.2f, and the kurtosis is: %4.2f' % (df['SIO2(WT%)'].mean(), df['SIO2(WT%)'].var(), df['SIO2(WT%)'].skew(), df['SIO2(WT%)'].kurtosis()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Realistic problem: data- or physics-informed synthetic data and noise\n",
    "\n",
    "In this case, we can create a time series that has the similar noise structure than the realistic noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
