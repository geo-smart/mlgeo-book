{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a438f0",
   "metadata": {},
   "source": [
    "# 2.2 Pandas, Basic Mapping\n",
    "\n",
    "This section aims to provide new skills in python to handle structured \"table\" data. \n",
    "\n",
    "Learning outcome:\n",
    "-   Manipulation of data frames (describing, filtering, ...) \n",
    "-   Learn about Lambda functions\n",
    "-   Intro to datetime objects\n",
    "-   Plotting data from data frames (histograms and maps)\n",
    "-   Introduction to Plotly, an interactive plotting package\n",
    "-   Introduction to CSV & Parquet\n",
    "\n",
    "\n",
    "We will work on several structured data sets: sensor metadata, seismic data product (earthquake catalog).\n",
    "\n",
    "First, we import all the modules we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dba5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'vscode' # writes as standalone html, \n",
    "# pio.renderers.default = 'iframe' # writes files as standalone html, \n",
    "# pio.renderers.default = 'png' # writes files as standalone html, \n",
    "# try notebook, jupyterlab, png, vscode, iframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab98dcb",
   "metadata": {},
   "source": [
    "# The Basics of Pandas \n",
    "\n",
    "Pandas are composed of ``Series`` and ``DataFrame``. ``Series`` are columns with attributes or keys. The ``DataFrame`` is a multi-dimensional table made up of ``Series``.\n",
    "\n",
    "We can create a DataFrame composed of series from scratch using Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4170fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'temperature' : [36,37,30,50],\n",
    "    'precipitation':[3,1,0,0]\n",
    "}\n",
    "my_pd = pd.DataFrame(data)\n",
    "print(my_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703b38e",
   "metadata": {},
   "source": [
    "Each (key,value) item in the dataframe correspond to a value in ``data``. To get the keys of the dataframe, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b911a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pd.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b5487",
   "metadata": {},
   "source": [
    "get a specific ``Series`` (different from the array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_pd.temperature[:])\n",
    "print(type(my_pd.temperature[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ac46bd",
   "metadata": {},
   "source": [
    "to get the _value_ of a specific key (e.g., temperature), at a specific index (e.g., 2) type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_pd.temperature[2])\n",
    "print(type(my_pd.temperature[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6792c",
   "metadata": {},
   "source": [
    "# Reading a DataFrame from a CSV file\n",
    "\n",
    "We can read a pandas directly from a standard file. Here you will read a catatalog of earthquakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f82af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quake = pd.read_csv(\"Global_Quakes_IRIS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce4345",
   "metadata": {},
   "source": [
    "Now you use the ``head`` function to display what is in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter answer here\n",
    "quake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906162b",
   "metadata": {},
   "source": [
    "Display the depth using two ways to use the pandas object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quake.depth)\n",
    "print(quake['depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112525e6",
   "metadata": {},
   "source": [
    "Calculate basic statitics of the data using the function ``describe``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45616ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quake.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0caf7d",
   "metadata": {},
   "source": [
    "Calculate mean and median of specific ``Series``, for example depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e77418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer it here\n",
    "print(quake.depth.mean())\n",
    "print(quake.depth.median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6b47f",
   "metadata": {},
   "source": [
    "## Simple Python Functions\n",
    "We will now practice how to modify the content of the DataFrame using functions. We will take the example that we want to change the depth values from meters to kilometers. First we can define this operation as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f06004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts a value in meters to a value in kilometers\n",
    "m2km = 1000 # this is defined as a global variable\n",
    "def meters2kilometers(x):\n",
    "    return x/m2km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now test it using the first element of the quake DataFrame\n",
    "meters2kilometers(quake.depth[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aee24d",
   "metadata": {},
   "source": [
    "Let's define another function that uses a local instead of global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822787a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meters2kilometers2(x):\n",
    "    m2km2=1000\n",
    "    return x/m2km2\n",
    "# m2km2 is a local variable and cannot be called outside of the function. Prove it next by inquiring its value in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4618282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m2km2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c71928",
   "metadata": {},
   "source": [
    "We now discuss the **lambda** functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we apply it on the entire Series\n",
    "meters2kilometers(quake.depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d351e",
   "metadata": {},
   "source": [
    "We can also define this very basic function as a **lambda** function. There are several ways of doing an operation on all rows of a column. The first option is to use the map function.\n",
    "\n",
    "If you are not familiar with lambda function in Python, look at:\n",
    "\n",
    "https://realpython.com/python-lambda/\n",
    "\n",
    "We will practice a bit lambda functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the equivalent in lambda is:\n",
    "lambda_meters2kilometers = lambda x:x/1000\n",
    "# x is the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a463e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply it to the entire series\n",
    "lambda_meters2kilometers(quake.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24982f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add several variables into lambda functions\n",
    "remove_anything = lambda x,y:x-y\n",
    "remove_anything(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5fe1c1",
   "metadata": {},
   "source": [
    "We will now use a lambda function to scale the depth values to km. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quake.depth.map(lambda p: p/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc0072",
   "metadata": {},
   "source": [
    "This did not affect the values of the DataFrame, check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "quake.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2f975",
   "metadata": {},
   "source": [
    "Instead, you could overwrite ``quake.depth=X``. Try two approaches but just do it once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af325f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type answer below\n",
    "quake.depth=quake.depth.map(lambda x:x/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or like this\n",
    "# quake.depth=quake.depth.apply(lambda x:x/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccc622",
   "metadata": {},
   "source": [
    "Plot a histogram of the depth distributions using matplotlib function ``hist``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here\n",
    "plt.hist(quake.depth,100)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Quake depth (km)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f708b5",
   "metadata": {},
   "source": [
    "You can use the interactive plotting package Plotly. First we will show a histogram of the event depth using the function ``histogram``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(quake,   #specify what dataframe to use\n",
    "             x=\"depth\",  #specify the variable for the histogram \n",
    "             nbins=50,       #number of bins for the histogram \n",
    "             height=400,     #dimensions of the figure\n",
    "             width=600);\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684bc7d",
   "metadata": {},
   "source": [
    "We will now make a new plot of the location of the earthquakes. We will use Plotly tool. \n",
    "\n",
    "The markersize will be scaled with the earthquake magnitude. To do so, we add a ``marker_size`` series in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "quake['marker_size'] =np.fix(np.exp(quake['magnitude'])) # add marker size as exp(mag)\n",
    "quake['magnitude bin'] = 0.5*np.fix(2*quake['magnitude']) # add marker size as exp(mag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211fc83",
   "metadata": {},
   "source": [
    "## Mapping using Plotly\n",
    "\n",
    "Now we will plot the earthquakes locations on a map using the Plotly package. More tutorials on [Plotly](https://plotly.com/). Input of the function in the function is self-explanatory and typical of Python's function. The code [documentation](https://plotly.com/python/scatter-plots-on-maps/) of Plotly scatter_geo lists the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(quake,\n",
    "                     lat='latitude',lon='longitude', \n",
    "                     range_color=(6,9),\n",
    "                     height=600, width=600,\n",
    "                     size='marker_size', color='magnitude',\n",
    "                     hover_name=\"description\",\n",
    "                     hover_data=['description','magnitude','depth']);\n",
    "fig.update_geos(resolution=110, showcountries=True)\n",
    "fig.update_geos(resolution=110, showcountries=True,projection_type=\"orthographic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62e8a4",
   "metadata": {},
   "source": [
    "The data was sorted by time. We now want to sort and show the data instead by magnitude. We use the pandas function ``sort`` to create a new DataFrame with sorted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes2plot=quake.sort_values(by='magnitude bin')\n",
    "\n",
    "quakes2plot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070d810",
   "metadata": {},
   "source": [
    "Now we will plot again using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(quakes2plot,\n",
    "                     lat='latitude',lon='longitude', \n",
    "                     range_color=(6,9),\n",
    "                     height=600, width=600,\n",
    "                     size='marker_size', color='magnitude',\n",
    "                     hover_name=\"description\",\n",
    "                     hover_data=['description','magnitude','depth']);\n",
    "fig.update_geos(resolution=110, showcountries=True)\n",
    "# fig.update_geos(resolution=110, showcountries=True,projection_type=\"orthographic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc6849",
   "metadata": {},
   "source": [
    "## Creating a new DataFrame from a text file\n",
    "\n",
    "The python package pandas is also very useful to parse many text files that are more or less formated as one observation per row and one column for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2662f",
   "metadata": {},
   "source": [
    "As an example, we are going to look at the list of seismic stations from the Northern California seismic network, available [here](http://ncedc.org/ftp/pub/doc/NC.info/NC.channel.summary.day):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://ncedc.org/ftp/pub/doc/NC.info/NC.channel.summary.day'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3737498",
   "metadata": {},
   "source": [
    "However, many options are available if the file is not well formatted. See more in this [tutorial](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets the file linked in the URL page and convert it to a string\n",
    "s = requests.get(url).content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this will convert the string, decode it , and make it a table\n",
    "data = pd.read_csv(io.StringIO(s.decode('utf-8')), header=None, skiprows=2, sep='\\s+', usecols=list(range(0, 13)))\n",
    "# because columns/keys were not assigned, assign them now\n",
    "data.columns = ['station', 'network', 'channel', 'location', 'rate', 'start_time', 'end_time', 'latitude', 'longitude', 'elevation', 'depth', 'dip', 'azimuth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a04924",
   "metadata": {},
   "source": [
    "Let us look at the data. They are now stored into a pandas dataframe. Read the top of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39168b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896206be",
   "metadata": {},
   "source": [
    "We can output the first element of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28662a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7799bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba79a1",
   "metadata": {},
   "source": [
    "The DataFrame may have bad values. A typical data cleaning involves removing Nan and Zeros for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a698f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data=data[data.longitude!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23510633",
   "metadata": {},
   "source": [
    "Use Plotly to map the stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf74a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(data,\n",
    "                     lat='latitude',lon='longitude', \n",
    "                     range_color=(6,9),\n",
    "                     height=600, width=600,\n",
    "                     hover_name=\"station\",\n",
    "                     hover_data=['network','station','channel','rate']);\n",
    "fig.update_geos(resolution=110, showcountries=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fdd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(data,\n",
    "                     lat='latitude',lon='longitude', \n",
    "                     range_color=(6,9),mapbox_style=\"carto-positron\",\n",
    "                     height=600, width=500,\n",
    "                     hover_name=\"station\",\n",
    "                     hover_data=['network','station','channel','rate']);\n",
    "fig.update_layout(title=\"Northern California Seismic Network\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991c460",
   "metadata": {},
   "source": [
    "## Pandas: data selection\n",
    "We can filter the data with the value taken by a given column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.station=='KCPB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38240e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two stations, use the typical \"OR\" |\n",
    "data.loc[(data.station=='KCPB') | (data.station=='KHBB')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f128ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two stations, use the typical \"AND\" &\n",
    "data.loc[(data.station=='KCPB') & (data.channel=='HNZ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or like this\n",
    "data.loc[data.station.isin(['KCPB', 'KHBB'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cf1c9",
   "metadata": {},
   "source": [
    "We can access to a brief summary of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86eb768",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.station.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1aed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.elevation.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e821e4",
   "metadata": {},
   "source": [
    "We can perform standard operations on the whole data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f17636",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dea1f",
   "metadata": {},
   "source": [
    "In the case of a categorical variable, we can get the list of possile values that this variable can take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.channel.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750a7ec",
   "metadata": {},
   "source": [
    "and get the number of times that each value is taken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50049411",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.station.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f2364",
   "metadata": {},
   "source": [
    "The second option is to use the apply function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_elevation_mean=data.elevation.unique().mean()\n",
    "def remean_elevation(row):\n",
    "    row.elevation = row.elevation - data_elevation_mean\n",
    "    return row\n",
    "data.apply(remean_elevation, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfaf7a3",
   "metadata": {},
   "source": [
    "We can also carry out simple operations on columns, provided they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "netsta=(data.network + '.' + data.station)\n",
    "print(netsta)\n",
    "print(type(netsta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "netsta=(data.network + '.' + data.station).values\n",
    "print(netsta)\n",
    "print(type(netsta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4800d2",
   "metadata": {},
   "source": [
    "A useful feature is to group the rows depending on the value of a categorical variable, and then apply the same operation to all the groups. For instance, we want to know how many times each station appears in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb628370",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('station').station.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104a322",
   "metadata": {},
   "source": [
    "We can have access to the data type of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2becd",
   "metadata": {},
   "source": [
    "Here, pandas does not recognize the start_time and end_time columns as a datetime format, so we cannot use datetime operations on them. We first need to convert these columns into a datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aceba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.start_time.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['start_time'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform column from string into datetime format\n",
    "startdate = pd.to_datetime(data['start_time'], format='%Y/%m/%d,%H:%M:%S')\n",
    "data['start_time'] = startdate\n",
    "print(data['start_time'] )\n",
    "type(data['start_time'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for end times\n",
    "# Avoid 'OutOfBoundsDatetime' error with year 3000\n",
    "enddate = data['end_time'].str.replace('3000', '2025')\n",
    "enddate = pd.to_datetime(enddate, format='%Y/%m/%d,%H:%M:%S')\n",
    "data['end_time'] = enddate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe088ce",
   "metadata": {},
   "source": [
    "We can now look when each seismic station was installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('station').apply(lambda df: df.start_time.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107f1b9",
   "metadata": {},
   "source": [
    "The ``agg`` function allows to carry out several operations to each group of rows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86283e",
   "metadata": {},
   "source": [
    "Select the stations that were deployed first and recovered last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2fe517",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['station']).agg({'start_time':lambda x: min(x), 'end_time':lambda x: max(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8509ce2",
   "metadata": {},
   "source": [
    "We can also make groups by selecting the values of two categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['station', 'channel']).agg({'start_time':lambda x: min(x), 'end_time':lambda x: max(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5c978",
   "metadata": {},
   "source": [
    "Previously, we just printed the output, but we can also store it in a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data.groupby(['station', 'channel']).agg({'start_time':lambda x: min(x), 'end_time':lambda x: max(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77003692",
   "metadata": {},
   "source": [
    "Print the new dataframe and look at the rows indexes. Anything wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ceaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a14e87",
   "metadata": {},
   "source": [
    "When we select only some rows, the index is not automatically reset to start at 0. We can do it manually. Many functions in pandas have also an option to reset the index, and option to transform the dataframe in place, instead of saving the results in another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e91221",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c76c3",
   "metadata": {},
   "source": [
    "It is also possible to sort the dataset by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped.sort_values(by='start_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdcd7c",
   "metadata": {},
   "source": [
    "We can apply the sorting to several columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped.sort_values(by=['start_time', 'end_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23573492",
   "metadata": {},
   "source": [
    "## CSV vs Parquet\n",
    "\n",
    "Parquet is a compressed data format that stores and compress the culumns. It is fast for I/O and compact formt.\n",
    "\n",
    "Save ``data`` into a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e8b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit data.to_csv(\"my_metadata.csv\")\n",
    "!ls -lh my_metadata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15631b4c",
   "metadata": {},
   "source": [
    "Try and save in Parquet, compare time and memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit data.to_parquet(\"my_metadata.pq\")\n",
    "!ls -lh my_metadata.pq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlgeo_sk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6825af05e3ea1f79f5651bdd3095330bdaee3a1e3958825bcb0ebbb42c21bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
