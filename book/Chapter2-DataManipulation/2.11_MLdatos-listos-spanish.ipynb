{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.11 ML-datos listos\n",
    "\n",
    "\n",
    "Preparar y preprocesar los datos para integrarlos en el flujo de trabajo del aprendizaje automático es fundamental para un buen proyecto de aprendizaje automático.\n",
    "\n",
    "Haga clic en [<img src=\"../img/teaching.png\" width=\"200\" >](../slides/MLReadyDatasets.pdf \"lecture slides\") para obtener las diapositivas.\n",
    "\n",
    "1. **Considera el problema** \n",
    "\n",
    "    Antes de saltar a un algoritmo específico, defina el problema en los *términos más generales*. Formularse a uno mismo y a los demás cuál es la cuestión. ¿Se trata de transformar $A$ en $B$? ¿Predecir $Y$ a partir de $X$? ¿Determinar cómo se relaciona una variable con otra?  Si el problema es computable, entonces es probable que pueda abordarse utilizando algún método ML.\n",
    "\n",
    "2. **¿Qué es posible desde un punto de vista realista?** \n",
    "    * Revisar la literatura existente (¡no necesariamente literatura específica de ML!). \n",
    "    * Si los expertos sólo pueden conseguir una precisión de $x$ para alguna tarea, ese debería ser su primer punto de referencia. Si la precisión de $x$ es \"suficientemente buena\", entonces la solución de ML puede que no necesite mejorarla.\n",
    "\n",
    "3. **Investigar enfoques generales** \n",
    "    * Si el problema implica el reconocimiento de texturas en imágenes, lea artículos que describan tanto la historia como las soluciones más avanzadas a ese problema general. \n",
    "    * Del mismo modo, si el proyecto consiste en dividir los datos en clases en función de varias variables, lea artículos sobre métodos de clasificación.\n",
    "    * Al igual que en el paso anterior, hágase una idea de lo que es posible para su pregunta general. \n",
    "    * Determine si el enfoque final será *estrecho* o *general* (y en qué medida).\n",
    "\n",
    "4. **Compilar los datos**\n",
    "    * Coloca los datos en una ubicación (por ejemplo, tu carpeta de inicio). \n",
    "    * Este proceso puede llevar algún tiempo, así que hazlo pronto.\n",
    "    * Independientemente de cómo reúna los datos, debe documentar cada paso.\n",
    "\n",
    "5. **Organiza los datos** en formatos legibles por la máquina y estructuras de datos que puedan ser manipuladas automáticamente en el flujo de trabajo ML:\n",
    "    * organizar los datos en arrays numpy, Xarrays, o pandas. \n",
    "    * guardar los datos y sus atributos en Zarr, H5, CSV.\n",
    "    * almacenar en una sola carpeta\n",
    "    * no transformar y sobrescribir los datos en bruto.\n",
    "\n",
    "6.  **Caracterizar los datos**\n",
    "    * Explorar las propiedades estadísticas de los datos (dibujar histogramas, distribuciones, gráficos cruzados, matrices de correlación). Guarde los guiones de toda la exploración de datos.\n",
    "    * Cuál será la entrada real de datos.\n",
    "    * Cuáles serán las salidas/etiquetas.\n",
    "\n",
    "\n",
    "7. **Considere las manipulaciones de los datos** extraiga características de los datos como primer paso hacia la reducción de la dimensionalidad:\n",
    "    * extraer características estadísticas, temporales o espectrales (usar tsfresh, tsfel, ...)\n",
    "    * Transformar los datos en el espacio de Fourier o Wavelet (utilizar el módulo scipy fft o cwt).\n",
    "    * Reducir la dimensión mediante PCA o ICA de los datos. Guarde estas características en un archivo o metadatos (utilice el módulo PCA o FastICA de scikit-learn). La reducción adicional de características podría ser:\n",
    "        + La *selección* de características encuentra las dimensiones que explican los datos sin pérdida de información y termina con una dimensionalidad más pequeña de los datos de entrada.  Un enfoque de *selección hacia delante* empieza con una variable que disminuye más el error y añade una a una.  Una *selección hacia atrás* comienza con todas las variables y las elimina una a una.\n",
    "\n",
    "8. **Considerar el aumento de datos\n",
    "    * Supongamos que tiene un conjunto de datos pequeño[^1]. Una cosa que puede hacer para solucionar este problema es aumentar sus datos (por ejemplo, crear copias modificadas de sus datos).\n",
    "\n",
    "    * Realice un bootstrap de sus datos. O utilice métodos Monte Carlo para propagar incertidumbres. Si tienes imágenes, inclínalas, estíralas, rótalas y espejalas. \n",
    "\n",
    "9. **Guarde el flujo de trabajo de procesamiento de datos de datos brutos a datos de características. \n",
    "    * Utilice el módulo scitkit-learn [Pipeline](!https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). \n",
    "    * Escribir un script python para reproducir el pre-procesamiento.\n",
    "\n",
    "\n",
    "[^1]: La definición de \"pequeño\" depende del problema. 1000 observaciones pueden ser más que suficientes para análisis de regresión simples. El mismo número de observaciones puede no ser adecuado para tareas de segmentación de imágenes. Considere la extensión de su espacio de problemas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c2df93b363d800c8a9b94963221f1be1d8deaf6a76f83b6b9a486ad05d69583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
