{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Formatos de datos\n",
    "\n",
    "En este tutorial, manipularemos la estructura de datos desde y hacia varios formatos de datos.\n",
    "\n",
    "\n",
    "Los formatos que soportan datos no estructurados (no relacionales) son:\n",
    "- JSON: JavaScript Object Notation, un formato de archivo estándar abierto que utiliza texto legible por humanos. Los datos pueden ser pares atributo-valor y matrices. Es independiente del lenguaje. La sintaxis es la siguiente\n",
    "```\n",
    "{\n",
    "  \"nombre\": \"John\",\n",
    "  \"apellido\": \"Smith\",\n",
    "  \"estaVivo\": verdadero,\n",
    "  \"edad\": 27,\n",
    "  \"dirección\": {\n",
    "    \"calle\": \"21 2nd Street\",\n",
    "    \"ciudad\": \"New York\",\n",
    "    \"estado\": \"NY\",\n",
    "    \"CodigoPostal\": \"10021-3100\"\n",
    "  }\n",
    "```\n",
    "La codificación de caracteres es UTF-8. Los tipos de datos en archivos JSON pueden ser números, cadena, booleano, matriz, obkect (colección de pares nombre-valor), null. Más información sobre JSON en el [curso EarthDataScience](!https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/apis-in-python/).\n",
    "\n",
    "\n",
    "Los principales formatos que admiten datos ráster pixelizados son:\n",
    "- \n",
    "**GeoTIFF**: norma de metadatos que permite incluir información de georreferenciación en un archivo TIFF (Tagged Image File Format).  **GeoTIFF** está mejorado para ser optimizado para la nube.\n",
    "- GeoJSON**: GeoJSON es un formato para codificar una variedad de estructuras de datos geográficos en el formato JSON.\n",
    "\n",
    "\n",
    "Los formatos que admiten datos tabulares son\n",
    "- CSV\n",
    "- Parquet\n",
    "\n",
    "\n",
    "Los formatos de datos para grandes datos heterogéneos (diferentes tipos de datos):\n",
    "- NetCDF4\n",
    "- HDF5\n",
    "- Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile , os, io\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pycrs\n",
    "import rasterio\n",
    "import h5py\n",
    "import rasterio\n",
    "import netCDF4 as nc\n",
    "import wget\n",
    "\n",
    "\n",
    "from folium.plugins import MarkerCluster\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datos raster\n",
    "\n",
    "### 1.1 rasterio para leer GeoTIFF\n",
    "\n",
    "Los datos raster son datos pixelados (o cuadriculados) en los que cada píxel está asociado a una ubicación geográfica específica. El valor de un píxel puede ser continuo (por ejemplo, la elevación) o categórico (por ejemplo, el uso del suelo).\n",
    "\n",
    "El paquete python ``rasterio``, con documentación [aquí](!https://rasterio.readthedocs.io/en/latest/), y que puede leer formatos como ``GeoTIFF`` y ``GeoJSON``.\n",
    "\n",
    "Ver materiales introductorios adicionales de [EarthDataScience](!https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/), y tutoriales de la [GeoHackweek](!https://geohackweek.github.io/raster/).\n",
    "\n",
    "\n",
    "\n",
    "Descargaremos archivos de topografía que se encuentran en esta [página](!https://www.naturalearthdata.com/downloads/50m-raster-data/50m-cross-blend-hypso/), pero almacenados en una carpeta de Dropbox.\n",
    "\n",
    "El nombre del archivo es `HYP_50M_SR` y es un archivo comprimido.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga los datos utilizando wget.\n",
    "fname = 'HYP_50M_SR'\n",
    "wget.download(\"https://www.dropbox.com/s/r75ecms0bvyqaca/\"+str(fname)+\"?dl=1\") # anote el último carácter como cadena para solicitar el propio archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo de datos se guardará en el directorio de inicio, queremos moverlo a una carpeta ``data``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.replace(fname+\".zip\", './data/'+fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descomprimir el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"./data/\"+fname+\"/\",exist_ok=True)\n",
    "# wget.download(url,out=\"HYP_50M_SR\") # this does not work on the hub\n",
    "z = zipfile.ZipFile('./data/'+fname+\".zip\")\n",
    "z.extractall(\"./data/\"+fname+\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a obtener el Mapa Digital de Elevaciones. Abrimos el archivo descomprimido utilizando el paquete ``rasterio``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = rasterio.open(\"./data/\"+fname+\"/\"+fname+\".tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elevation.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las dimensiones de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Puedes adivinar cómo llamar a los tipos de datos de la entrada del archivo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe abajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y en los límites del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elevation.transform * (0, 0)) # North West corner\n",
    "print(elevation.transform * (elevation.width, elevation.height)) # South East corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He aquí la proyección utilizada para los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo interpretar los datos: Hay tres capas para los tres colores rojo, verde y azul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elevation.colorinterp[0])\n",
    "print(elevation.colorinterp[1])\n",
    "print(elevation.colorinterp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(elevation.read(1)), np.max(elevation.read(1)))\n",
    "print(np.min(elevation.read(2)), np.max(elevation.read(2)))\n",
    "print(np.min(elevation.read(3)), np.max(elevation.read(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = elevation.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Geopandas para leer GeoJSON\n",
    "\n",
    "Los GeoTIFF no son el único tipo de ficheros que podemos leer con geopandas. Veamos un ejemplo de lectura de datos de un fichero geojson (que es un caso especial de fichero json con coordenadas geográficas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nps.gov/lib/npmap.js/4.0.0/examples/data/national-parks.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks = gpd.read_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a graficar los datos.\n",
    "\n",
    "folium es un buen paquete de Python para la visualización. El [Geohackweek tutorial on Folium](!https://github.com/geohackweek/tutorial_contents/blob/master/visualization/notebooks/foliumTutorial.ipynb) también es informativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[40, -100], zoom_start=4)\n",
    "folium.GeoJson(parks).add_to(m)\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a centrarnos en los parques del Estado de Washington:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_WA = parks.iloc[[94, 127, 187, 228, 286, 294, 295, 297, 299, 300, 302]].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de ubicaciones para añadir ventanas emergentes al mapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = []\n",
    "for index in range(0, len(parks_WA)):\n",
    "    location = [parks_WA['geometry'][index].y, parks_WA['geometry'][index].x]\n",
    "    locations.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[47, -121], zoom_start=7)\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "for point in range(0, len(locations)):\n",
    "    folium.Marker(location = locations[point], popup=parks_WA['Name'].iloc[point]).add_to(marker_cluster)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Formatos jerárquicos: NETCDF4 Y HDF5\n",
    "\n",
    "Los formatos de datos jerárquicos están diseñados para almacenar grandes cantidades de datos en un único archivo. Imitan un sistema de archivos (por ejemplo, una estructura de datos en forma de árbol con directorios anidados) en un único archivo.  Existen dos formatos de datos jerárquicos dominantes (HDF5 y NETCDF4), y uno emergente para la nube (Zarr). Los formatos jerárquicos en general pueden almacenar muchos tipos de datos (numéricos frente a cadenas).\n",
    "\n",
    "## HDF5\n",
    "El Formato Jerárquico de Datos versión 5 (HDF5), es un formato de archivo de código abierto que soporta datos grandes, complejos y heterogéneos. HDF5 utiliza una estructura similar a un \"directorio de archivos\" que permite organizar los datos dentro del archivo de muchas formas estructuradas diferentes, como podría hacer con los archivos de su ordenador. El formato HDF5 también permite incrustar metadatos, por lo que es _autodescriptivo_.\n",
    "Los archivos HDF5 son autodescriptivos, lo que significa que todos los elementos (el propio archivo, los grupos y los conjuntos de datos) pueden tener metadatos asociados que describen la información contenida en el elemento.\n",
    "\n",
    "\n",
    "Ejemplo de estructura HDF:\n",
    "- Conjuntos de datos, que son matrices multidimensionales tipadas\n",
    "- Grupos, que son estructuras contenedoras que pueden contener conjuntos de datos y otros grupos\n",
    "\n",
    "\n",
    "<img src=\"hdf5_structure4.jpeg\" alt=\"Ilustración de un conjunto de datos H5 \" />\n",
    "Figura: Ejemplo de datos HDF5. Encontrado en [neonscience](https://www.neonscience.org/resources/learning-hub/tutorials/about-hdf5)\n",
    "\n",
    "## Netcdf\n",
    "\n",
    "El formulario común de datos de red, o **netCDF**, se creó a principios de los años 90 y se propuso resolver algunos de los problemas que planteaba trabajar con matrices N-dimensionales. Netcdf es una colección de formatos de datos binarios autodescriptivos e independientes de la máquina y de herramientas de software que facilitan la creación, el acceso y el intercambio de datos científicos almacenados en matrices N-dimensionales, junto con metadatos que describen el contenido de cada matriz. Netcdf fue creado por la comunidad científica del clima en un momento en que los modelos climáticos regionales empezaban a producir archivos de salida cada vez más grandes. La versión 4 de NetCDF es ahora un subconjunto de HDF5.\n",
    "\n",
    "### Manejo de matrices de gran tamaño\n",
    "Los formatos NetCDF y H5 no limitan el tamaño de los archivos. Sin embargo, cualquier herramienta de análisis que lea datos de una matriz NetCDF en memoria para alguna operación computacional estará limitada por la memoria disponible de esa máquina en particular. \n",
    "\n",
    "### Pero lento en I/O\n",
    "Al leer un archivo jerárquico, se escanea todo el árbol de la estructura de datos desde el nodo raíz hacia abajo. Dado que hay que hacerlo cada vez que un usuario realiza una consulta, la lectura de H5 y Netcdf es **lenta**. Hay métodos más rápidos\n",
    "\n",
    "\n",
    "Vamos a descargar un mapa geológico almacenado en formato netCDF en Dropbox. Los datos originales se pueden encontrar en la [base de datos USGS](!https://www.sciencebase.gov/catalog/item/5cfeb4cce4b0156ea5645056). (https://doi.org/10.3133/ofr20191081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el marco geológico\n",
    "file1 = wget.download(\"https://www.dropbox.com/s/wdb25puxh3u07dj/NCM_GeologicFrameworkGrids.nc?dl=1\") #\"./data/NCM_GeologicFrameworkGrids.nc\"\n",
    "# Descargar las rejillas de coordenadas\n",
    "file2 = wget.download(\"https://www.dropbox.com/s/wdb25puxh3u07dj/NCM_SpatialGrid.nc?dl=1\") #\"./data/NCM_GeologicFrameworkGrids.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mover los datos\n",
    "os.replace(file1,'./data/'+file1)\n",
    "os.replace(file2,'./data/'+file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer los datos\n",
    "geology = nc.Dataset('./data/'+file1)\n",
    "grid = nc.Dataset('./data/'+file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geology['Surface Elevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(geology['Surface Elevation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geology['Surface Elevation'][3246, 1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = grid['x'][0:4901, 0:3201]\n",
    "y = grid['y'][0:4901, 0:3201]\n",
    "elevation = geology['Surface Elevation'][0:4901, 0:3201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(x, y, elevation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zarr\n",
    "\n",
    "\n",
    "Zarr es un formato de datos optimizado para la nube que maneja conjuntos de datos heterogéneos.\n",
    "\n",
    "En el siguiente ejercicio, utilizaremos los conjuntos de datos abiertos air_temperature de Xarray y los guardaremos en un archivo Zarr.\n",
    "\n",
    "Vamos a trabajar en grupos para :\n",
    "- Descargar los datos xarray\n",
    "- Guardarlos en un fichero, informar sobre el tiempo y el tamaño del conjunto de datos.\n",
    "- Leerlo de nuevo y comprobar de nuevo el tiempo de escritura y los tiempos de lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c2df93b363d800c8a9b94963221f1be1d8deaf6a76f83b6b9a486ad05d69583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
